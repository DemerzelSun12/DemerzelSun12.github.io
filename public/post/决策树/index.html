<!doctype html>
<html
  lang="zh-cn" 
  
    data-theme-mode="auto"
  
>
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=13926&amp;path=livereload" data-no-instant defer></script>
    
    <meta charset="utf-8" />
<meta
  name="viewport"
  content="width=device-width, initial-scale=1, shrink-to-fit=no"
/>







  

<title>
  决策树 | Demerzel
</title>
<meta
  name="description"
  content="浮沉在世 人事变迁"
/>










<script>
  window.siteConfig = JSON.parse("{\"anchor_icon\":null,\"clipboard\":{\"copyright\":{\"content\":\"本文版权：本博客所有文章除特别声明外，均采用 BY-NC-SA 许可协议。转载请注明出处！\",\"count\":50,\"enable\":false},\"fail\":\"复制失败 (ﾟ⊿ﾟ)ﾂ\",\"success\":\"复制成功(*^▽^*)\"},\"code_block\":{\"expand\":true},\"icon_font\":\"4552607_0khxww3tj3q9\",\"outdate\":{\"daysago\":180,\"enable\":false,\"message\":\"本文最后更新于 {time}，请注意文中内容可能已经发生变化。\"}}");
</script>






  







  
  
  
    
  

  
  
  
    
  

  
    

<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
<link
  rel="preload"
  as="style"
  href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7cNoto%20Serif%20SC:400,400italic,700,700italic%7c&amp;display=swap"
/>
<link
  rel="stylesheet"
  href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7cNoto%20Serif%20SC:400,400italic,700,700italic%7c&amp;display=swap"
  media="print"
  onload="this.media='all'"
/>







  <link
    rel="preload"
    href="//at.alicdn.com/t/c/font_4552607_0khxww3tj3q9.woff2"
    as="font"
    type="font/woff2"
    crossorigin="anonymous"
  />



  






 <link rel="stylesheet" href="/css/loader.css" />




  <meta property="og:type" content="website" />
  <meta property="og:title" content="决策树 | Demerzel" />
  <meta
    property="og:description"
    content="浮沉在世 人事变迁"
  />
  <meta property="og:url" content="http://localhost:13926/post/%E5%86%B3%E7%AD%96%E6%A0%91/" />
  <meta
    property="og:site_name"
    content="Demerzel&#39;s Blog"
  />
  <meta
    property="og:image"
    content="/images/featureimages/6.jpg"
  />
  <meta property="article:author" content="Demerzel" />
  <meta property="article:published_time" content="2020-08-15T22:01:42&#43;00:00" />
  <meta property="article:modified_time" content="2020-08-15T22:01:42&#43;00:00" />
  
    <meta property="article:tag" content="算法机器学习" />
  
  
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:image" content="/images/featureimages/6.jpg" />
  
  
  
  
  




<link rel="shortcut icon" href="/favicon.ico">







 <link rel="stylesheet" href="/css/main.css" />





  <link
    rel="preload"
    as="style"
    href="https://npm.webcache.cn/photoswipe@5.4.4/dist/photoswipe.css"
    onload="this.onload=null;this.rel='stylesheet'"
  />






  <link
    rel="preload"
    as="style"
    href="https://npm.webcache.cn/katex@0.16.9/dist/katex.min.css"
    onload="this.onload=null;this.rel='stylesheet'"
  />








  

  
  
    
  
  
  
  
  
  
  
  <script
    src="https://npm.webcache.cn/pace-js@1.2.4/pace.min.js"
    
    
    
    
    integrity="sha384-k6YtvFUEIuEFBdrLKJ3YAUbBki333tj1CSUisai5Cswsg9wcLNaPzsTHDswp4Az8" crossorigin="anonymous"
  ></script>





  


  <link rel="stylesheet" href="https://npm.webcache.cn/@reimujs/aos@0.1.0/dist/aos.css" />





    
  </head>
  <body>
    
    
  <div id='loader'>
    <div class="loading-left-bg loading-bg"></div>
    <div class="loading-right-bg loading-bg"></div>
    <div class="spinner-box">
      <div class="loading-taichi rotate">
        
          <svg width="150" height="150" viewBox="0 0 1024 1024" class="icon" version="1.1" xmlns="https://www.w3.org/2000/svg" shape-rendering="geometricPrecision">
            <path d="M303.5 432A80 80 0 0 1 291.5 592A80 80 0 0 1 303.5 432z" fill="var(--red-1, #ff5252)" />
            <path d="M512 65A447 447 0 0 1 512 959L512 929A417 417 0 0 0 512 95A417 417 0 0 0 512 929L512 959A447 447 0 0 1 512 65z 
          M512 95A417 417 0 0 1 929 512A208.5 208.5 0 0 1 720.5 720.5L720.5 592A80 80 0 0 0 720.5 432A80 80 0 0 0 720.5 592L720.5 720.5A208.5 208.5 0 0 1 512 512A208.5 208.5 0 0 0 303.5 303.5A208.5 208.5 0 0 0 95 512A417 417 0 0 1 512 95z" fill="var(--red-1, #ff5252)" />
          </svg>
        
      </div>
      <div class="loading-word">少女祈祷中...</div>
    </div>
  </div>
  </div>
  <script>
    var time = null;
    var startLoading = () => {
      time = Date.now();
      document.getElementById('loader').classList.remove("loading");
    }
    var endLoading = () => {
      if (!time) {
        document.body.style.overflow = 'auto';
        document.getElementById('loader').classList.add("loading");
      } else {
        if (Date.now() - time > 500) {
          time = null;
          document.body.style.overflow = 'auto';
          document.getElementById('loader').classList.add("loading");
        } else {
          setTimeout(endLoading, 500 - (Date.now() - time));
          time = null;
        }
      }
    }
    window.addEventListener('DOMContentLoaded', endLoading);
    document.getElementById('loader').addEventListener('click', endLoading);
  </script>


<div id="copy-tooltip" style="pointer-events: none; opacity: 0; transition: all 0.2s ease; position: fixed;top: 50%;left: 50%;z-index: 999;transform: translate(-50%, -50%);color: white;background: rgba(0, 0, 0, 0.5);padding: 10px 15px;border-radius: 10px;">
</div>


    <div id="container">
      <div id="wrap">
        
<div id="header-nav">
  <nav id="main-nav">
    
      <span class="main-nav-link-wrap">
        <div class='main-nav-icon icon rotate'>
          
            
              &#xe62b;
            
          
        </div>
        <a class="main-nav-link" href="/">首页</a>
      </span>
    
      <span class="main-nav-link-wrap">
        <div class='main-nav-icon icon rotate'>
          
            
              &#xe62b;
            
          
        </div>
        <a class="main-nav-link" href="/archives">归档</a>
      </span>
    
      <span class="main-nav-link-wrap">
        <div class='main-nav-icon icon rotate'>
          
            
              &#xe62b;
            
          
        </div>
        <a class="main-nav-link" href="/about">关于</a>
      </span>
    
      <span class="main-nav-link-wrap">
        <div class='main-nav-icon icon rotate'>
          
            
              &#xe62b;
            
          
        </div>
        <a class="main-nav-link" href="/friend">友链</a>
      </span>
    
    <a id="main-nav-toggle" class="nav-icon"></a>
  </nav>
  <nav id="sub-nav">
    
    
  </nav>
</div>
<header id="header">
  
    <picture></picture>
    <img  fetchpriority="high" src="/images/featureimages/6.jpg" alt="决策树">
  

  <div id="header-outer">
    <div id="header-title">
      
        
        
          
        
  
        
          <a href="/" id="logo">
            <h1 data-aos="slide-up">决策树</h1>
          </a>
        
      
  
      
        
        
        <h2 id="subtitle-wrap" data-aos="slide-down">
          
        </h2>
      
    </div>
  </div>
</header>
        <div id="content"
          
          class="sidebar-right"  >
          <aside id="sidebar">
  
  
  
  <div class="sidebar-wrapper wrap-sticky">
    <div
      class="sidebar-wrap"
      data-aos="fade-up"
    >
      
        
          <div class="sidebar-toc-sidebar">
            <div class="sidebar-toc">
  <h3 class="toc-title">文章目录</h3>
  <div class="sidebar-toc-wrapper toc-div-class">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#一决策树模型与学习">一、决策树模型与学习</a>
      <ul>
        <li><a href="#11-决策树模型">1.1 决策树模型</a></li>
        <li><a href="#12-决策树与if-then规则">1.2 决策树与if-then规则</a></li>
        <li><a href="#13-决策树与条件概率分布">1.3 决策树与条件概率分布</a></li>
        <li><a href="#14-决策树学习">1.4 决策树学习</a></li>
      </ul>
    </li>
    <li><a href="#二特征选择">二、特征选择</a>
      <ul>
        <li><a href="#21-特征选择问题">2.1 特征选择问题</a></li>
        <li><a href="#22-信息增益">2.2 信息增益</a></li>
        <li><a href="#23-信息增益比">2.3 信息增益比</a></li>
      </ul>
    </li>
    <li><a href="#三决策树的生成">三、决策树的生成</a>
      <ul>
        <li><a href="#31-id3算法">3.1 ID3算法</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
          </div>
          <div class="sidebar-common-sidebar hidden">
            
<div class="sidebar-author">
  <img
    data-src="/images/avatar.jpg"
    data-sizes="auto"
    alt="Demerzel"
    class="lazyload"
  />
  <div class="sidebar-author-name">Demerzel</div>
  <div class="sidebar-description">浮沉在世 人事变迁</div>
</div>
<div class="sidebar-state">
  <div class="sidebar-state-article">
    <div>文章</div>
    
    <div class="sidebar-state-number">51</div>
  </div>
  <div class="sidebar-state-category">
    <div>分类</div>
    <div class="sidebar-state-number">
      18
    </div>
  </div>
  <div class="sidebar-state-tag">
    <div>标签</div>
    <div class="sidebar-state-number">28</div>
  </div>
</div>
<div class="sidebar-social">
  
    <div class="icon-email sidebar-social-icon">
      <a
        href="mailto:demerzelsun@gmail.com"
        itemprop="url"
        target="_blank"
        aria-label="email"
        rel="noopener external nofollow noreferrer"
      ></a>
    </div>
  
    <div class="icon-github sidebar-social-icon">
      <a
        href="https://github.com/demerzelsun12"
        itemprop="url"
        target="_blank"
        aria-label="github"
        rel="noopener external nofollow noreferrer"
      ></a>
    </div>
  
    <div class="icon-linkedin sidebar-social-icon">
      <a
        href="https://www.linkedin.com/in/xiao-sun-52a2a21b0/"
        itemprop="url"
        target="_blank"
        aria-label="linkedin"
        rel="noopener external nofollow noreferrer"
      ></a>
    </div>
  
</div>
<div class="sidebar-menu">
  
    <div class="sidebar-menu-link-wrap">
      <a
        class="sidebar-menu-link-dummy"
        href="/"
        aria-label="首页"
      ></a>
      <div class='sidebar-menu-icon icon rotate'>
        
          
            &#xe62b;
          
        
      </div>
      <div class="sidebar-menu-link">首页</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a
        class="sidebar-menu-link-dummy"
        href="/archives"
        aria-label="归档"
      ></a>
      <div class='sidebar-menu-icon icon rotate'>
        
          
            &#xe62b;
          
        
      </div>
      <div class="sidebar-menu-link">归档</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a
        class="sidebar-menu-link-dummy"
        href="/about"
        aria-label="关于"
      ></a>
      <div class='sidebar-menu-icon icon rotate'>
        
          
            &#xe62b;
          
        
      </div>
      <div class="sidebar-menu-link">关于</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a
        class="sidebar-menu-link-dummy"
        href="/friend"
        aria-label="友链"
      ></a>
      <div class='sidebar-menu-icon icon rotate'>
        
          
            &#xe62b;
          
        
      </div>
      <div class="sidebar-menu-link">友链</div>
    </div>
  
</div>

          </div>
        
      

      
        
          <div class="sidebar-btn-wrapper" style="position:static">
            <div class="sidebar-toc-btn current"></div>
            <div class="sidebar-common-btn"></div>
          </div>
        
      
    </div>
  </div>

  <div class="sidebar-widget">
    
  </div>
  
</aside>

          <section id="main">
  <article
  class="h-entry article"
  itemprop="blogPost"
  itemscope
  itemtype="https://schema.org/BlogPosting"
>
  <div
    class="article-inner"
    data-aos="fade-up"
  >
    <div class="article-meta">
      <div class="article-date">
  <span
    class="article-date-link"
    data-aos="zoom-in"
  >
    <time datetime="2020-08-15 22:01:42 &#43;0000 UTC" itemprop="datePublished"
      >2020-08-15</time
    >
    <time style="display: none;" id="post-update-time"
      >2020-08-15</time
    >
  </span>
</div>

      <div class="article-category">
  
    <a
      class="article-category-link"
      href="/categories/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0"
      data-aos="zoom-in"
      >机器学习</a
    >
  
</div>

    </div>
    <div class="hr-line"></div>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
      
        <h2 id="一决策树模型与学习">
<a class="header-anchor" href="#%e4%b8%80%e5%86%b3%e7%ad%96%e6%a0%91%e6%a8%a1%e5%9e%8b%e4%b8%8e%e5%ad%a6%e4%b9%a0"></a>
一、决策树模型与学习
</h2><p>  决策树是一种基本的分类与回归方法。决策树整体是一个树型结构，在分类的问题中，表示基于特征对实例进行分类的过程。可以认为是<code>if-then</code>的规则集合，也可以认为是定义在特征空间与类空间上的条件概率分布。
  优点是模型具有可读性，分类速度快。决策树学习通常分为三个步骤：特征选择、决策树生成和决策树的修剪。</p>
<ol>
<li>学习时，可以利用训练数据，根据损失函数的最小化原则建立决策树模型。</li>
<li>预测时，对新的数据，利用决策树模型进行分类。</li>
</ol>
<h3 id="11-决策树模型">
<a class="header-anchor" href="#11-%e5%86%b3%e7%ad%96%e6%a0%91%e6%a8%a1%e5%9e%8b"></a>
1.1 决策树模型
</h3><p>  <font size = 3 face="黑体"><strong>定义1 （决策树）</strong></font></p>
<p>  <font face = "楷体">分类决策树模型是一种描述对实例点进行分类的树型结构。由结点(<em>node</em>)和有向边(<em>directed edge</em>)组成。结点有两种类型：内部结点(<em>internal node</em>)和叶结点(<em>leaf node</em>)。内部结点表示一个特征或属性，叶节点表示一个类。</font>
  利用决策树分类，从根节点开始，对某一特征进行测试，根据分类结果，将其分配到其子节点；如此递归进行测试并分配，直到叶节点，最后将实例分配到叶节点的类中。图1-1是一个决策树的示意图，圆表示内部节点，方框表示叶节点。</p>
<center>
<img src="https://img-blog.csdnimg.cn/20200906093402365.png" width="50%" height="35%">
</center>
<center>
图1-1 决策树模型
</center>
<h3 id="12-决策树与if-then规则">
<a class="header-anchor" href="#12-%e5%86%b3%e7%ad%96%e6%a0%91%e4%b8%8eif-then%e8%a7%84%e5%88%99"></a>
1.2 决策树与if-then规则
</h3><p>  由决策树的根节点到叶节点的每一条路径构建一条规则；路径上的内部节点的特征对应着规则的条件，而叶节点的类对应着规则的结论。决策树的路径或其对应的<code>if-then</code>规则结合具有一个重要的性质：互斥且完备。即，每一个实例都被一条路径或规则覆盖，而且只被一条路径或规则覆盖。</p>
<h3 id="13-决策树与条件概率分布">
<a class="header-anchor" href="#13-%e5%86%b3%e7%ad%96%e6%a0%91%e4%b8%8e%e6%9d%a1%e4%bb%b6%e6%a6%82%e7%8e%87%e5%88%86%e5%b8%83"></a>
1.3 决策树与条件概率分布
</h3><p>  决策树还表示为定义在给定的特征条件下的类的条件概率分布。这些条件概率分布定义在特征空间的一个划分上。决策树将特征空间划分为互不相交的单元(<em>cell</em>)，并在单元上定义了一个类的概率分布。决策树的一条路径对应了划分中的一个单元。
  假设 $X$ 为表示特征的随机变量，$Y$ 为表示类的随机变量，那么这个条件概率分布可以表示为 $P\left(Y|X\right)$。$X$ 的取值与给定的划分下单元的集合，$Y$ 取值于类的集合。各叶节点上的条件概率往往偏向某一个类的概率较大，决策树在分类时会将该实例分配到条件概率较大的那一类去。
  图1-2表示了一种特征空间的划分与与之对应的决策树。</p>
<center>
<img src = "https://img-blog.csdnimg.cn/20200906100954231.png" width = "60%" height = "35%">
<img src = "https://img-blog.csdnimg.cn/20200906101121405.png" width = "60%" height = "35%">
</center>
<center>
图1-2 决策树对应于条件概率分布
</center>
<h3 id="14-决策树学习">
<a class="header-anchor" href="#14-%e5%86%b3%e7%ad%96%e6%a0%91%e5%ad%a6%e4%b9%a0"></a>
1.4 决策树学习
</h3><p>  假定给定训练数据集
</p>
$$
D=\left\{ \left( x_1,y_1 \right) ,\left( x_2,y_2 \right) ,\cdots ,\left( x_N,y_N \right) \right\} 
$$<p>
其中，$x_i=\left( x_{i}^{\left( 1 \right)},x_{i}^{\left( 2 \right)},\cdots ,x_{i}^{\left( n \right)} \right) ^{\text{T}}$ 为输入实例，$n$ 为特征个数，$y_i\in \left\{1,2,\cdots,K\right\}$ 为类标记，$i=1,2\cdots,N$，$N$ 为样本容量。决策树学习的目标是根据给定的训练数据集构建一个决策树模型，使其能够对新输入的实例进行正确分类。
  决策树的本质是从训练数据集中归纳出一组分类规则。与训练集相符的决策树可能有多个，也可能没有。目标是构建一个与训练数据集向矛盾较小的决策树，并且具有很好的泛化能力。
  决策树学习的损失函数通常是正则化的极大似然函数，学习策略的是以损失函数为目标函数的最小化。损失函数确定后，学习的目标变为在损失函数意义下的选择最优决策树的问题。因为从所有可能的决策树中选择合适的决策树属于 $NP$ 完全问题，因此实际中常常采用启发式方法，近似求解，这样得到的决策树为次最优的(<em>sub-optimal</em>)。
  决策树的学习算法通常是一个递归地选择最优特征，并根据该特征对训练数据进行分割，使得各个子数据集有一个最好的分类过程。这个过程也就是特征空间的划分，也是决策树的构建过程。然后递归分类，直到所有训练数据子集基本都被正确分类，这样就生成了一颗决策树。
  以上方法可能对训练数据集有一个很好的分类，但是对未知数据未必有很好的分类能力，很有可能发生过拟合的现象。因此我们需要对生成的树进行从叶到根进行剪枝，使树变得简单，由此拥有更好的泛化能力。具体做法是，去掉分类过于细致的叶节点，使其退回到父节点或更高的节点，然后将父节点或更高的节点变为叶节点。</p>
<h2 id="二特征选择">
<a class="header-anchor" href="#%e4%ba%8c%e7%89%b9%e5%be%81%e9%80%89%e6%8b%a9"></a>
二、特征选择
</h2><h3 id="21-特征选择问题">
<a class="header-anchor" href="#21-%e7%89%b9%e5%be%81%e9%80%89%e6%8b%a9%e9%97%ae%e9%a2%98"></a>
2.1 特征选择问题
</h3><p>  特征选择在于选择对数据集有分类能力的特征，以此提高决策树的效率。通常特征选择的标准是信息增益或信息增益比。</p>
<h3 id="22-信息增益">
<a class="header-anchor" href="#22-%e4%bf%a1%e6%81%af%e5%a2%9e%e7%9b%8a"></a>
2.2 信息增益
</h3><p>  首先给出熵和条件熵的概念。</p>
<p>  <font size = 3 face = "楷体">熵(<em>entopy</em>)</font>是表示随机变量不确定性的度量。设 $X$ 是表示随机变量不确定性的度量。设 $X$ 是一个取有限个值的离散随机变量，其概率分布为 $P\left(X=x_i\right)=p_i, i=1,2,\cdots,n$ 则随机变量 $X$ 的熵定义为
</p>
$$
H\left(X\right) = -\sum_{i=1}^n{p_i}\log p_i
$$<p>
若 $p_i=0$，则定义 $0\log 0=0$。通常上式的对数以 $2$ 或 $e$ 为底，这是熵的单位分别称为比特(<em>bit</em>)或纳特(<em>nat</em>)。由定义知，熵只依赖于 $X$ 的分布，与 $X$ 的取值无关，所以也将 $X$ 的熵记作 $H\left(p\right)$，即
</p>
$$
H\left(p\right)=-\sum_{i=1}^np_i\log p_i
$$<p>
  熵越大，随机变量的不确定性就越大。由定义可以验证
</p>
$$
0\le H\left(p\right)\le \log n
$$<p>
  当随机变量只取两个值时，例如 $1,0$ 时，即 $X$ 的分布为
</p>
$$
P\left(X=1\right)=p,\; P\left(X=0\right)=1-p,\; 0\le p\le 1
$$<p>
熵为
</p>
$$
H\left(p\right)=-\log_2p-\left(1-p\right)\log_2\left(1-p\right)
$$<p>
这时，熵 $H\left(p\right)$随概率 $p$ 变化的曲线如图1-3所示（单位为比特）。</p>
<center>
<img src = "https://img-blog.csdnimg.cn/20200906155438448.png" width = "40%" height = "35%">
</center>
<center>
图1-3 伯努利分布熵与概率的关系
</center>
<p>  当 $p=0$ 或 $p=1$ 时 $H\left(p\right)=0$，随机变量完全没有不确定性。当 $p=0.5$ 时，$H\left(p\right)=1$，熵取值最大，随机变量的不确定性最大。
  设有随机变量 $\left(X,Y\right)$，其联合概率分布为
</p>
$$
P\left(X=x_i,Y=y_i\right)=p_{ij},\; i=1,2,\cdots ,n; \; j=1,2,\cdots,m
$$<p>
条件熵 $H\left(Y|X\right)$ 表示在已知随机变量 $X$ 的条件下随机变量 $Y$ 的不确定性。随机变量 $X$给定条件下随机变量 $Y$ 的条件熵 $H\left(Y|X\right)$，定义为 $X$ 给定条件下 $Y$ 的条件概率分布的熵对 $X$ 的数学期望
</p>
$$
H\left(Y|X\right)=\sum_{i=1}^n{p_iH\left(Y|X=x_i\right)}
$$<p>
这里，$p_i=P\left(X=x_i\right)$，$i=1,2,\cdots,n$。
  当熵和条件熵中的概率由数据估计（一般是极大似然估计）得到时，所对应的熵和条件熵分别称为经验熵和经验条件熵。规定 $0\log 0=0$。
  信息增益表示得知特征 $X$ 的信息而使得类 $Y$ 的信息不确定性减小的程度。</p>
<p>  <font size = 3 face="黑体"><strong>定义2 （信息增益）</strong></font>
  <font face = "楷体">特征 $A$ 对训练数据集 $D$ 的信息增益 $g\left(D,A\right)$，定义为集合 $D$ 的经验熵 $H\left(D\right)$ 与特征 $A$ 给定条件下 $D$ 的经验条件熵 $H\left(D|A\right)$ 之差，即</font>
</p>
$$
g\left(D,A\right)=H\left(D\right)-H\left(D|A\right)
$$<p>
  决策树学习应用信息增益准则作为选择特征。对于给定的数据集 $D$ 和特征 $A$，经验熵 $H\left(D\right)$ 表示对数据集 $D$ 进行分类的不确定性。而经验条件熵 $H\left(D|A\right)$ 表示在特征 $A$ 给定条件下对数据集 $D$ 进行分类的不确定性。而二者的差，即信息增益，就是<strong>由于特征 $A$ 而使得对数据集 $D$ 的分类的不确定性的减少程度</strong>。显然，对于同一个数据集的不同特征，往往都有不同的信息增益，而信息增益大的特征具有更强的分类能力。</p>
<p>  <font size = 4><strong>算法 1（信息增益算法）</strong></font></p>
<p>  输入：训练数据集 $D$ 和特征 $A$，$\left| D \right|$ 为样本容量，设有 $K$ 个类 $C_k$，$k=1,2,\cdots,K$，$\left| C_k \right|$ 为属于 $C_k$ 的样本个数，$\sum_{k=1}^K{\left|C_k\right|}=\left|D\right|$。设特征 $A$ 有 $n$ 个不同的取值 $\left\{a_1,a_2,\cdots,a_n\right\}$，根据特征 $A$ 的取值将 $D$ 划分为 $n$ 个子集 $D_1,D_2,\cdots,D_n$，$\left|D_i\right|$ 为 $D_i$ 的样本个数，$\sum_{i=1}^n{\left|D_i\right|}=\left|D\right|$;</p>
<p>  输出：特征 $A$ 对训练数据集 $D$ 的信息增益$g\left(D,A\right)$。</p>
<ol>
<li>
<p>计算数据集 $D$ 的经验熵 $H\left(D\right)$;
</p>
$$
H\left( D \right) =-\sum_{k=1}^K{\frac{\left| C_k \right|}{\left| D \right|}\log _2}\frac{\left| C_k \right|}{\left| D \right|}
$$</li>
<li>
<p>计算特征 $A$ 对数据集 $D$ 的经验条件熵 $H\left(D|A\right)$</p>
</li>
</ol>
$$
H\left( D |A\right) =\sum_{i=1}^n{\frac{\left| D_i \right|}{\left| D \right|}H\left( D_i \right)}=-\sum_{i=1}^n{\frac{\left| D_i \right|}{\left| D \right|}\sum_{k=1}^K{\frac{\left| D_{ik} \right|}{\left| D_i \right|}\log _2\frac{\left| D_{ik} \right|}{\left| D_i \right|}}}
$$<ol start="3">
<li>计算信息增益</li>
</ol>
$$
g\left(D,A\right)=H\left(D\right)-H\left(D|A\right)
$$<p>  <em>Python</em>代码如下</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">calc_H_D</span><span class="p">(</span><span class="n">trainLabelArr</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    计算数据集D的经验熵
</span></span></span><span class="line"><span class="cl"><span class="s2">    :param trainLabelArr:当前数据集的标签集
</span></span></span><span class="line"><span class="cl"><span class="s2">    :return: 经验熵
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 初始化为0</span>
</span></span><span class="line"><span class="cl">    <span class="n">H_D</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 将当前所有标签放入集合中，这样只要有的标签都会在集合中出现，且出现一次。</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 遍历该集合就可以遍历所有出现过的标记并计算其Ck</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 这么做有一个很重要的原因：首先假设一个背景，当前标签集中有一些标记已经没有了，比如说标签集中</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 没有0（这是很正常的，说明当前分支不存在这个标签）。</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 计算Cl和D并求和时，由于没有0，那么C0=0，此时C0/D0=0,log2(C0/D0) = log2(0)，事实上0并不在log的定义区间内，出现了问题</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 所以使用集合的方式先知道当前标签中都出现了那些标签，随后对每个标签进行计算，如果没出现的标签那一项就</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 不在经验熵中出现（未参与，对经验熵无影响），保证log的计算能一直有定义</span>
</span></span><span class="line"><span class="cl">    <span class="n">trainLabelSet</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="n">label</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">trainLabelArr</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 遍历每一个出现过的标签</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">trainLabelSet</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 计算|Ck|/|D|</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># trainLabelArr == i：当前标签集中为该标签的的位置</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 例如a = [1, 0, 0, 1], c = (a == 1): c == [True, false, false, True]</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># trainLabelArr[trainLabelArr == i]：获得为指定标签的样本</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># trainLabelArr[trainLabelArr == i].size：获得为指定标签的样本的大小，即标签为i的样本</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 数量，就是|Ck|</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># trainLabelArr.size：整个标签集的数量（也就是样本集的数量），即|D|</span>
</span></span><span class="line"><span class="cl">        <span class="n">p</span> <span class="o">=</span> <span class="n">trainLabelArr</span><span class="p">[</span><span class="n">trainLabelArr</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">size</span> <span class="o">/</span> <span class="n">trainLabelArr</span><span class="o">.</span><span class="n">size</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 对经验熵的每一项累加求和</span>
</span></span><span class="line"><span class="cl">        <span class="n">H_D</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">p</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 返回经验熵</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">H_D</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">calcH_D_A</span><span class="p">(</span><span class="n">trainDataArr_DevFeature</span><span class="p">,</span> <span class="n">trainLabelArr</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    计算经验条件熵
</span></span></span><span class="line"><span class="cl"><span class="s2">    :param trainDataArr_DevFeature:切割后只有feature那列数据的数组
</span></span></span><span class="line"><span class="cl"><span class="s2">    :param trainLabelArr: 标签集数组
</span></span></span><span class="line"><span class="cl"><span class="s2">    :return: 经验条件熵
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 初始为0</span>
</span></span><span class="line"><span class="cl">    <span class="n">H_D_A</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 在featue那列放入集合中，是为了根据集合中的数目知道该feature目前可取值数目是多少</span>
</span></span><span class="line"><span class="cl">    <span class="n">trainDataSet</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="n">label</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">trainDataArr_DevFeature</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 对于每一个特征取值遍历计算条件经验熵的每一项</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">trainDataSet</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 计算H(D|A)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># trainDataArr_DevFeature[trainDataArr_DevFeature == i].size / trainDataArr_DevFeature.size:|Di| / |D|</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># calc_H_D(trainLabelArr[trainDataArr_DevFeature == i]):H(Di)</span>
</span></span><span class="line"><span class="cl">        <span class="n">H_D_A</span> <span class="o">+=</span> <span class="n">trainDataArr_DevFeature</span><span class="p">[</span><span class="n">trainDataArr_DevFeature</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">size</span> <span class="o">/</span> <span class="n">trainDataArr_DevFeature</span><span class="o">.</span><span class="n">size</span> \
</span></span><span class="line"><span class="cl">                 <span class="o">*</span> <span class="n">calc_H_D</span><span class="p">(</span><span class="n">trainLabelArr</span><span class="p">[</span><span class="n">trainDataArr_DevFeature</span> <span class="o">==</span> <span class="n">i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 返回得出的条件经验熵</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">H_D_A</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">calcBestFeature</span><span class="p">(</span><span class="n">trainDataList</span><span class="p">,</span> <span class="n">trainLabelList</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    计算信息增益最大的特征
</span></span></span><span class="line"><span class="cl"><span class="s2">    :param trainDataList: 当前数据集
</span></span></span><span class="line"><span class="cl"><span class="s2">    :param trainLabelList: 当前标签集
</span></span></span><span class="line"><span class="cl"><span class="s2">    :return: 信息增益最大的特征及最大信息增益值
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 将数据集和标签集转换为数组形式</span>
</span></span><span class="line"><span class="cl">    <span class="n">trainDataArr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">trainDataList</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">trainLabelArr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">trainLabelList</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 获取当前特征数目，也就是数据集的横轴大小</span>
</span></span><span class="line"><span class="cl">    <span class="n">featureNum</span> <span class="o">=</span> <span class="n">trainDataArr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 初始化最大信息增益</span>
</span></span><span class="line"><span class="cl">    <span class="n">maxG_D_A</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 初始化最大信息增益的特征</span>
</span></span><span class="line"><span class="cl">    <span class="n">maxFeature</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 信息增益的算法：</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 1.计算数据集D的经验熵H(D)</span>
</span></span><span class="line"><span class="cl">    <span class="n">H_D</span> <span class="o">=</span> <span class="n">calc_H_D</span><span class="p">(</span><span class="n">trainLabelArr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 对每一个特征进行遍历计算</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">featureNum</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 2.计算条件经验熵H(D|A)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 由于条件经验熵的计算过程中只涉及到标签以及当前特征，为了提高运算速度（全部样本</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 做成的矩阵运算速度太慢，需要剔除不需要的部分），将数据集矩阵进行切割</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 数据集在初始时刻是一个Arr = 60000*784的矩阵，针对当前要计算的feature，在训练集中切割下</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Arr[:, feature]这么一条来，因为后续计算中数据集中只用到这个</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># trainDataArr[:, feature]:在数据集中切割下这么一条</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># trainDataArr[:, feature].flat：将这么一条转换成竖着的列表</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># np.array(trainDataArr[:, feature].flat)：再转换成一条竖着的矩阵，大小为60000*1（只是初始是</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 这么大，运行过程中是依据当前数据集大小动态变的）</span>
</span></span><span class="line"><span class="cl">        <span class="n">trainDataArr_DevideByFeature</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">trainDataArr</span><span class="p">[:,</span> <span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">flat</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 3.计算信息增益G(D|A)    G(D|A) = H(D) - H(D | A)</span>
</span></span><span class="line"><span class="cl">        <span class="n">G_D_A</span> <span class="o">=</span> <span class="n">H_D</span> <span class="o">-</span> <span class="n">calcH_D_A</span><span class="p">(</span><span class="n">trainDataArr_DevideByFeature</span><span class="p">,</span> <span class="n">trainLabelArr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 不断更新最大的信息增益以及对应的feature</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">G_D_A</span> <span class="o">&gt;</span> <span class="n">maxG_D_A</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">maxG_D_A</span> <span class="o">=</span> <span class="n">G_D_A</span>
</span></span><span class="line"><span class="cl">            <span class="n">maxFeature</span> <span class="o">=</span> <span class="n">feature</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">maxFeature</span><span class="p">,</span> <span class="n">maxG_D_A</span>
</span></span></code></pre></div><h3 id="23-信息增益比">
<a class="header-anchor" href="#23-%e4%bf%a1%e6%81%af%e5%a2%9e%e7%9b%8a%e6%af%94"></a>
2.3 信息增益比
</h3><p>  以信息增益作为划分数据集的特征，存在<strong>偏向于选择取值较多的特征</strong>的问题。使用信息增益比(<em>information gain ratio</em>)可以对这个问题校正。也可以依据这个选择特征作为划分。
  <font size = 3 face="黑体"><strong>定义3 （信息增益比）</strong></font>
  <font face = "楷体">特征 $A$ 对训练数据集 $D$ 的信息增益比 $g_R\left(D,A\right)$，定义为其信息增益 $g\left(D,A\right)$ 与训练数据集 $D$ 关于特征 $A$ 的值的熵 $H_A\left(D\right)$ 之比，即</font>
</p>
$$
g_R\left(D,A\right)=\cfrac{g\left(D,A\right)}{H_A\left(D\right)}
$$<p>
其中，
</p>
$$
H_A\left( D \right) =-\sum_{i=1}^n{\frac{\left| D_i \right|}{\left| D \right|}\log _2}\frac{\left| D_i \right|}{\left| D \right|}
$$<p>
$n$ 是特征 $A$ 取值的个数。</p>
<h2 id="三决策树的生成">
<a class="header-anchor" href="#%e4%b8%89%e5%86%b3%e7%ad%96%e6%a0%91%e7%9a%84%e7%94%9f%e6%88%90"></a>
三、决策树的生成
</h2><h3 id="31-id3算法">
<a class="header-anchor" href="#31-id3%e7%ae%97%e6%b3%95"></a>
3.1 ID3算法
</h3><p>  <em>ID3</em>算法的核心是在决策树各个节点上应用<strong>信息增益准则</strong>选择特征</p>

      
    </div>
    <footer class="article-footer">
      

      

      

      

      

      

      

      
      <ul class="article-tag-list" itemprop="keywords">
  
    <li class="article-tag-list-item" data-aos="zoom-in">
      <a
        class="article-tag-list-link"
        href="/tags/%e7%ae%97%e6%b3%95"
        rel="tag"
        >算法</a
      >
    </li>
  
    <li class="article-tag-list-item" data-aos="zoom-in">
      <a
        class="article-tag-list-link"
        href="/tags/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0"
        rel="tag"
        >机器学习</a
      >
    </li>
  
</ul>

    </footer>
  </div>
  
    
  <nav
    id="article-nav"
    data-aos="fade-up"
  >
    
      <div class="article-nav-link-wrap article-nav-link-left">
        
          <img
            data-src="images/featureimages/3.jpg"
            data-sizes="auto"
            alt="感知机"
            class="lazyload"
          />
        
        <a href="/post/%E6%84%9F%E7%9F%A5%E6%9C%BA/"></a>
        <div class="article-nav-caption">前一篇</div>
        <h3 class="article-nav-title">
          
            感知机
          
        </h3>
      </div>
    

    
      <div class="article-nav-link-wrap article-nav-link-right">
        
          <img
            data-src="images/featureimages/6.jpg"
            data-sizes="auto"
            alt="k近邻法"
            class="lazyload"
          />
        
        <a href="/post/k%E8%BF%91%E9%82%BB%E6%B3%95/"></a>
        <div class="article-nav-caption">后一篇</div>
        <h3 class="article-nav-title">
          
            k近邻法
          
        </h3>
      </div>
    
  </nav>


  
</article>






  

  

  

  

  



</section>
        </div>
        



  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  



<footer id="footer">
  <div style="width: 100%; overflow: hidden">
    <div class="footer-line"></div>
  </div>
  <div id="footer-info">
    
    <div>
      <span class="icon-copyright"></span>
      
        2020 -
        2025
      
      <span class="footer-info-sep "></span>
      Demerzel
    </div>
    
      <div>
        基于&nbsp;<a
          href="https://gohugo.io/"
          target="_blank"
          >Hugo</a
        >&nbsp; Theme.<a
          href="https://github.com/D-Sketon/hugo-theme-reimu"
          target="_blank"
          >Reimu</a
        >
      </div>
    
    
      <div>
        <span class="icon-brush"
          >&nbsp;
            155.1k
          </span
        >
        &nbsp;|&nbsp;
        <span class="icon-coffee">&nbsp;
          
          

          05:36
        </span>
      </div>
    
    
    
    
  </div>
</footer>

        
          <div class="sidebar-top">
            <div class="sidebar-top-taichi "></div>
            <div class="arrow-up"></div>
          </div>
        
        <div id="mask" class="hide"></div>
      </div>
      <nav id="mobile-nav">
  <div class="sidebar-wrap">
    
      
        <div class="sidebar-toc-sidebar">
          <div class="sidebar-toc">
  <h3 class="toc-title">文章目录</h3>
  <div class="sidebar-toc-wrapper toc-div-class">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#一决策树模型与学习">一、决策树模型与学习</a>
      <ul>
        <li><a href="#11-决策树模型">1.1 决策树模型</a></li>
        <li><a href="#12-决策树与if-then规则">1.2 决策树与if-then规则</a></li>
        <li><a href="#13-决策树与条件概率分布">1.3 决策树与条件概率分布</a></li>
        <li><a href="#14-决策树学习">1.4 决策树学习</a></li>
      </ul>
    </li>
    <li><a href="#二特征选择">二、特征选择</a>
      <ul>
        <li><a href="#21-特征选择问题">2.1 特征选择问题</a></li>
        <li><a href="#22-信息增益">2.2 信息增益</a></li>
        <li><a href="#23-信息增益比">2.3 信息增益比</a></li>
      </ul>
    </li>
    <li><a href="#三决策树的生成">三、决策树的生成</a>
      <ul>
        <li><a href="#31-id3算法">3.1 ID3算法</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
        </div>
        <div class="sidebar-common-sidebar hidden">
          
<div class="sidebar-author">
  <img
    data-src="/images/avatar.jpg"
    data-sizes="auto"
    alt="Demerzel"
    class="lazyload"
  />
  <div class="sidebar-author-name">Demerzel</div>
  <div class="sidebar-description">浮沉在世 人事变迁</div>
</div>
<div class="sidebar-state">
  <div class="sidebar-state-article">
    <div>文章</div>
    
    <div class="sidebar-state-number">51</div>
  </div>
  <div class="sidebar-state-category">
    <div>分类</div>
    <div class="sidebar-state-number">
      18
    </div>
  </div>
  <div class="sidebar-state-tag">
    <div>标签</div>
    <div class="sidebar-state-number">28</div>
  </div>
</div>
<div class="sidebar-social">
  
    <div class="icon-email sidebar-social-icon">
      <a
        href="mailto:demerzelsun@gmail.com"
        itemprop="url"
        target="_blank"
        aria-label="email"
        rel="noopener external nofollow noreferrer"
      ></a>
    </div>
  
    <div class="icon-github sidebar-social-icon">
      <a
        href="https://github.com/demerzelsun12"
        itemprop="url"
        target="_blank"
        aria-label="github"
        rel="noopener external nofollow noreferrer"
      ></a>
    </div>
  
    <div class="icon-linkedin sidebar-social-icon">
      <a
        href="https://www.linkedin.com/in/xiao-sun-52a2a21b0/"
        itemprop="url"
        target="_blank"
        aria-label="linkedin"
        rel="noopener external nofollow noreferrer"
      ></a>
    </div>
  
</div>
<div class="sidebar-menu">
  
    <div class="sidebar-menu-link-wrap">
      <a
        class="sidebar-menu-link-dummy"
        href="/"
        aria-label="首页"
      ></a>
      <div class='sidebar-menu-icon icon rotate'>
        
          
            &#xe62b;
          
        
      </div>
      <div class="sidebar-menu-link">首页</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a
        class="sidebar-menu-link-dummy"
        href="/archives"
        aria-label="归档"
      ></a>
      <div class='sidebar-menu-icon icon rotate'>
        
          
            &#xe62b;
          
        
      </div>
      <div class="sidebar-menu-link">归档</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a
        class="sidebar-menu-link-dummy"
        href="/about"
        aria-label="关于"
      ></a>
      <div class='sidebar-menu-icon icon rotate'>
        
          
            &#xe62b;
          
        
      </div>
      <div class="sidebar-menu-link">关于</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a
        class="sidebar-menu-link-dummy"
        href="/friend"
        aria-label="友链"
      ></a>
      <div class='sidebar-menu-icon icon rotate'>
        
          
            &#xe62b;
          
        
      </div>
      <div class="sidebar-menu-link">友链</div>
    </div>
  
</div>

        </div>
      
    
  </div>
  
    
      <div class="sidebar-btn-wrapper">
        <div class="sidebar-toc-btn current"></div>
        <div class="sidebar-common-btn"></div>
      </div>
    
  
</nav>

    </div>
    
    
    
    






  
  
    
  
  
  
  
  
  
  
  <script
    src="https://npm.webcache.cn/lazysizes@5.3.2/lazysizes.min.js"
    
    
    
    
    integrity="sha384-3gT/vsepWkfz/ff7PpWNUeMzeWoH3cDhm/A8jM7ouoAK0/fP/9bcHHR5kHq2nf&#43;e" crossorigin="anonymous"
  ></script>




  
  
    
  
  
  
  
  
  
  
  <script
    src="https://npm.webcache.cn/clipboard@2.0.11/dist/clipboard.min.js"
    
    
    
    
    integrity="sha384-J08i8An/QeARD9ExYpvphB8BsyOj3Gh2TSh1aLINKO3L0cMSH2dN3E22zFoXEi0Q" crossorigin="anonymous"
  ></script>











  
      
      <script src="/js/main.js" ></script>
      



  





  
      
      <script src="/js/aos.js" ></script>
      

  <script>
    var aosInit = () => {
      AOS.init({
        duration: 1000,
        easing: "ease",
        once: true,
        offset: 50,
      });
    };
    if (document.readyState === "loading") {
      document.addEventListener("DOMContentLoaded", aosInit);
    } else {
      aosInit();
    }
  </script>








  
      
      <script src="/js/pjax_main.js" data-pjax></script>
      





  

  
  
    
  
  
  
  
  
  
  
  <script
    src="https://npm.webcache.cn/mouse-firework@0.1.1/dist/index.umd.js"
    
    
    
    
    integrity="sha384-8LyaidD9GPxQQgLJO/WRw/O2h3BoNq/ApI/ecpvM6RsrCz2qP2ppBXUKihP4V/2d" crossorigin="anonymous"
  ></script>


<script>
  if (window.firework) {
    const options = JSON.parse("{\"excludeelements\":[\"a\",\"button\"],\"particles\":[{\"colors\":[\"var(--red-1)\",\"var(--red-2)\",\"var(--red-3)\",\"var(--red-4)\"],\"duration\":[1200,1800],\"easing\":\"easeOutExpo\",\"move\":[\"emit\"],\"number\":20,\"shape\":\"circle\",\"shapeOptions\":{\"alpha\":[0.3,0.5],\"radius\":[16,32]}},{\"colors\":[\"var(--red-0)\"],\"duration\":[1200,1800],\"easing\":\"easeOutExpo\",\"move\":[\"diffuse\"],\"number\":1,\"shape\":\"circle\",\"shapeOptions\":{\"alpha\":[0.2,0.5],\"lineWidth\":6,\"radius\":20}}]}");
    options.excludeElements = options.excludeelements;
    delete options.excludeelements;
    window.firework(options);
  }
</script>








<div id="lazy-script">
  <div>
    
      
      
        
      
      <script data-pjax>
        window.REIMU_POST = {
          author: "Demerzel",
          title: "决策树",
          url: "http:\/\/localhost:13926\/post\/%E5%86%B3%E7%AD%96%E6%A0%91\/",
          description: "一种分类与回归的方法——决策树",
          cover: "http:\/\/localhost:13926\/images\/featureimages\/6.jpg",
        };
      </script>
    
    
    
      





  
      
      <script src="/js/insert_highlight.js" data-pjax></script>
      

      
      
      
      
      <script type="module" data-pjax>
        
        const PhotoSwipeLightbox = (await safeImport("https:\/\/npm.webcache.cn\/photoswipe@5.4.4\/dist\/photoswipe-lightbox.esm.min.js", "sha384-DiL6M\/gG\u002bwmTxmCRZyD1zee6lIhawn5TGvED0FOh7fXcN9B0aZ9dexSF\/N6lrZi\/")).default;
        
        const pswp = () => {
          if (_$$('.article-entry a.article-gallery-item').length > 0) {
            new PhotoSwipeLightbox({
              gallery: '.article-entry',
              children: 'a.article-gallery-item',
              
              pswpModule: () => safeImport("https:\/\/npm.webcache.cn\/photoswipe@5.4.4\/dist\/photoswipe.esm.min.js", "sha384-WkkO3GCmgkC3VQWpaV8DqhKJqpzpF9JoByxDmnV8\u002boTJ7m3DfYEWX1fu1scuS4\u002bs")
              
            }).init();
          }
          if(_$$('.article-gallery a.article-gallery-item').length > 0) {
            new PhotoSwipeLightbox({
              gallery: '.article-gallery',
              children: 'a.article-gallery-item',
              
              pswpModule: () => safeImport("https:\/\/npm.webcache.cn\/photoswipe@5.4.4\/dist\/photoswipe.esm.min.js", "sha384-WkkO3GCmgkC3VQWpaV8DqhKJqpzpF9JoByxDmnV8\u002boTJ7m3DfYEWX1fu1scuS4\u002bs")
              
            }).init();
          }
          window.lightboxStatus = 'done';
          window.removeEventListener('lightbox:ready', pswp);
        }
        if(window.lightboxStatus === 'ready') {
          pswp()
        } else {
          window.addEventListener('lightbox:ready', pswp);
        }
      </script>
      







  

  

  

  

  



      
    
    
      
      
        <script data-pjax>
          window.MathJax = JSON.parse("[{\"loader\":{\"load\":[\"input/asciimath\",\"[tex]/noerrors\"]},\"options\":{\"ignoreHtmlClass\":\"tex2jax_ignore\",\"processHtmlClass\":\"tex2jax_process\",\"skipHtmlTags\":[\"script\",\"noscript\",\"style\",\"textarea\",\"pre\",\"code\"]},\"tex\":{\"autoload\":{\"color\":[],\"colorv2\":[\"color\"]},\"displayMath\":[[\"$$\",\"$$\"],[\"\\\\\\\\[\",\"\\\\\\\\]\"]],\"inlineMath\":[[\"$\",\"$\"],[\"\\\\\\\\(\",\"\\\\\\\\)\"]],\"packages\":{\"[+]\":[\"noerrors\"]},\"processEnvironments\":true,\"processEscapes\":true,\"tags\":\"ams\",\"useLabelIds\":true}}]")[0];
        </script>
        

  
  
    
  
  
  
  
  
  
  
  <script
    src="https://npm.webcache.cn/mathjax@3.2.2/es5/tex-mml-chtml.js"
    defer
    
    data-pjax
    
    integrity="sha384-Wuix6BuhrWbjDBs24bXrjf4ZQ5aFeFWBuKkFekO2t8xFU0iNaLQfp2K6/1Nxveei" crossorigin="anonymous"
  ></script>


      
    
  </div>
</div>






  <script>
    if ('serviceWorker' in navigator) {
      navigator.serviceWorker.getRegistrations().then((registrations) => {
        for (let registration of registrations) {
          registration.unregister();
        }
      });
    }
  </script>


<script>
  const reimuCopyright = String.raw`
   ______     ______     __     __    __     __  __    
  /\  == \   /\  ___\   /\ \   /\ "-./  \   /\ \/\ \   
  \ \  __<   \ \  __\   \ \ \  \ \ \-./\ \  \ \ \_\ \  
   \ \_\ \_\  \ \_____\  \ \_\  \ \_\ \ \_\  \ \_____\ 
    \/_/ /_/   \/_____/   \/_/   \/_/  \/_/   \/_____/ 
                                                    
  `;
  console.log(String.raw`%c ${reimuCopyright}`, "color: #ff5252;");
  console.log(
    "%c Theme.Reimu" + " %c https://github.com/D-Sketon/hugo-theme-reimu ",
    "color: white; background: #ff5252; padding:5px 0;",
    "padding:4px;border:1px solid #ff5252;",
  );
</script>






    
  </body>
</html>
